{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:     median_house_value   R-squared:                       0.644\n",
      "Model:                            OLS   Adj. R-squared:                  0.643\n",
      "Method:                 Least Squares   F-statistic:                     2572.\n",
      "Date:                Fri, 08 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        16:04:30   Log-Likelihood:            -1.5757e+05\n",
      "No. Observations:               12828   AIC:                         3.152e+05\n",
      "Df Residuals:                   12818   BIC:                         3.152e+05\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                      -1.002e+06   5.26e+04    -19.024      0.000    -1.1e+06   -8.98e+05\n",
      "longitude                  -1.821e+04    914.855    -19.906      0.000      -2e+04   -1.64e+04\n",
      "latitude                   -1.806e+04    892.679    -20.235      0.000   -1.98e+04   -1.63e+04\n",
      "housing_median_age           505.1476     43.943     11.496      0.000     419.013     591.282\n",
      "total_rooms                  -11.6526      1.461     -7.974      0.000     -14.517      -8.788\n",
      "total_bedrooms               133.9681     10.469     12.797      0.000     113.448     154.489\n",
      "population                   -63.2859      1.733    -36.528      0.000     -66.682     -59.890\n",
      "households                   112.1361     11.034     10.163      0.000      90.507     133.765\n",
      "median_income               3.565e+04    504.867     70.612      0.000    3.47e+04    3.66e+04\n",
      "ocean_proximity_<1H OCEAN  -4.778e+05   2.68e+04    -17.858      0.000    -5.3e+05   -4.25e+05\n",
      "ocean_proximity_INLAND     -5.237e+05   2.59e+04    -20.218      0.000   -5.75e+05   -4.73e+05\n",
      "ocean_proximity_ISLAND              0          0        nan        nan           0           0\n",
      "ocean_proximity_NEAR BAY            0          0        nan        nan           0           0\n",
      "ocean_proximity_NEAR OCEAN          0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     2706.030   Durbin-Watson:                   0.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7768.669\n",
      "Skew:                           1.108   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.102   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_percentage_error,r2_score\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.preprocessing import PowerTransformer,RobustScaler,StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#loading the data\n",
    "class Loading:\n",
    "    '''Class to load data from a specified path using a given read method.'''\n",
    "    def __init__(self, path_,read_method_):\n",
    "        self.path=path_\n",
    "        self.read_method=read_method_\n",
    "        self.data=self.getData()\n",
    "    def getData(self):\n",
    "        '''Loads the data from the specified path using the read method.'''\n",
    "        return self.read_method(self.path)\n",
    "\n",
    "#filling the data\n",
    "class FillNa:\n",
    "    '''Class to fill or drop missing values (NaN) based on the specified strategy.'''\n",
    "    def __init__(self,data,strategy):\n",
    "        self.data=data\n",
    "        self.strategy=strategy\n",
    "        self.filledData=self.apply()\n",
    "\n",
    "    def apply(self):\n",
    "        '''Applies the filling or dropping method based on the strategy.'''\n",
    "        if self.strategy == \"drop\":\n",
    "            return self.dropNa()\n",
    "        else:\n",
    "            return self.fillingNullValues()\n",
    "        \n",
    "    def fillingNullValues(self):\n",
    "        '''Fills missing numerical values using SimpleImputer.'''\n",
    "        data = pd.DataFrame(self.data) \n",
    "        numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
    "        imputer = SimpleImputer(missing_values=np.nan, strategy=self.strategy)\n",
    "        data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n",
    "        return data\n",
    "\n",
    "    def dropNa(self):\n",
    "        '''Drops rows containing missing values.'''\n",
    "        return self.data.dropna()\n",
    "\n",
    "#onehotencoding the data\n",
    "class OneHotEncoding:\n",
    "    '''Class to apply OneHotEncoding on categorical columns of the data.'''\n",
    "    def __init__(self,data,categoricalColumns):\n",
    "        self.data=data\n",
    "        self.categoricalColumns=categoricalColumns\n",
    "        self.oneHotEncodedData=self.oneHotEncoding()\n",
    "\n",
    "    def oneHotEncoding(self):\n",
    "        '''Performs OneHotEncoding on the specified categorical columns.'''\n",
    "        ohe=OneHotEncoder(handle_unknown='ignore',sparse_output=False).set_output(transform='pandas')\n",
    "        ohetransform=ohe.fit_transform(self.data[self.categoricalColumns]).astype(int)\n",
    "        data= pd.concat([self.data,ohetransform],axis=1).drop(columns=self.categoricalColumns)    \n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "#finding outliers\n",
    "class Outlier:\n",
    "    '''Class to detect and remove outliers using specified method (IQR).'''\n",
    "    def __init__(self,oneHotEncodedData,method):\n",
    "        self.oneHotEncodedData=oneHotEncodedData\n",
    "        self.method=method\n",
    "        if(method_outlier_==\"iqr\"):\n",
    "            self.cleanedData=self.iqrOutlierDetectionAndRemoval()\n",
    "\n",
    "    def iqrOutlierDetectionAndRemoval(self):\n",
    "        '''Removes outliers using IQR method.'''\n",
    "        data=pd.DataFrame(self.oneHotEncodedData)\n",
    "        dffeatureNames=data.columns\n",
    "        cleaned_df = data.copy()\n",
    "        for col in dffeatureNames:\n",
    "                Q1 = cleaned_df[col].quantile(0.25)\n",
    "                Q3 = cleaned_df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1        \n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n",
    "\n",
    "        cleaned_df = cleaned_df.reset_index(drop=True)\n",
    "        return pd.DataFrame(cleaned_df)\n",
    "        \n",
    "#splitting into train and test\n",
    "class SplittingData:\n",
    "    '''Class to split the dataset into features and target variable.'''\n",
    "    def __init__(self,data,targetColumn):\n",
    "        self.data=data\n",
    "        self.targetColumn=targetColumn\n",
    "        self.X,self.y=self.splitData()\n",
    "        \n",
    "    def splitData(self):\n",
    "        '''Splits data into features (X) and target variable (y).'''\n",
    "        X = self.data.drop(columns=self.targetColumn)  \n",
    "        y = self.data[self.targetColumn]\n",
    "        return X,y\n",
    "\n",
    "#splitting train and test\n",
    "class TrainTestSplit:\n",
    "    '''Class to split data into training and testing sets.'''\n",
    "    def __init__(self, X,y,**kwargs):\n",
    "        self.X=X\n",
    "        self.y=y\n",
    "        self.testingSize=kwargs['testingSize']\n",
    "        self.randomState=kwargs['random_State']\n",
    "        self.xTrain, self.xTest, self.yTrain, self.yTest = self.trainTestSplit()\n",
    "        \n",
    "    def trainTestSplit(self):\n",
    "        '''Splits data into training and testing sets based on specified parameters.'''\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=self.testingSize, random_state=self.randomState)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "#standardization xtrain\n",
    "class Standardization:\n",
    "    '''Class to apply standardization (PowerTransformation) on training and test data.'''\n",
    "    def __init__(self, **kwargs): \n",
    "        self.xTrain = kwargs['Xtrain']  \n",
    "        self.xTest = kwargs['XTest']\n",
    "        self.method = kwargs['method']\n",
    "        self.pt = None\n",
    "        self.xTrain_transformed = self.powerTransformer()\n",
    "        self.xTest_transformed = self.powerTransformTest()\n",
    "        \n",
    "    def powerTransformer(self):\n",
    "        '''Applies power transformation on training data.'''\n",
    "        data = pd.DataFrame(self.xTrain).copy()\n",
    "        not_one_hot_columns = [\n",
    "            col for col in data.columns \n",
    "            if data[col].dtype in [np.int64, np.float64] and not set(data[col].dropna()) <= {0, 1, 0.0, 1}\n",
    "        ]\n",
    "        self.pt = PowerTransformer(method=self.method)\n",
    "        data[not_one_hot_columns] = self.pt.fit_transform(data[not_one_hot_columns])\n",
    "        return data\n",
    "\n",
    "    def powerTransformTest(self):\n",
    "        '''Applies power transformation on test data.'''\n",
    "        data = pd.DataFrame(self.xTest).copy()\n",
    "        not_one_hot_columns = [\n",
    "            col for col in data.columns \n",
    "            if data[col].dtype in [np.int64, np.float64] and not set(data[col].dropna()) <= {0, 1, 0.0, 1}\n",
    "        ]\n",
    "        data[not_one_hot_columns] = self.pt.transform(data[not_one_hot_columns])\n",
    "        return data\n",
    "\n",
    "\n",
    "#model fitting\n",
    "class ModelFitting():\n",
    "    '''Class to fit a specified model on the training data.'''\n",
    "    def __init__(self, model,xtrain,ytrain): \n",
    "        self.xtrain=xtrain\n",
    "        self.model=model\n",
    "        self.ytrain=ytrain   \n",
    "        self.fittedModel=self.modelFit()\n",
    "\n",
    "    def modelFit(self):\n",
    "        '''Fits the specified model on the training data.'''\n",
    "        fittedModel = self.model.fit(self.xtrain, self.ytrain)\n",
    "        return fittedModel\n",
    "\n",
    "#model evaluation\n",
    "class Evaluation():\n",
    "    def __init__(self, XTest,ytest,regressionMetrics,fittedModel):\n",
    "        '''Class to evaluate the fitted model using specified regression metrics.''' \n",
    "        self.xtest=XTest\n",
    "        self.ytest=ytest\n",
    "        self.regressionMetrics=regressionMetrics\n",
    "        self.fittedModel=fittedModel\n",
    "        self.score=self.metrics()\n",
    "    \n",
    "    def metrics(self):\n",
    "        '''Evaluates the model performance using the provided regression metrics.'''\n",
    "        xtest=pd.DataFrame(self.xtest)\n",
    "        yPred=self.fittedModel.predict(xtest)\n",
    "        score=self.regressionMetrics(self.ytest,yPred)\n",
    "        return score\n",
    "\n",
    "\n",
    "#statmodelsummary\n",
    "class StatModelOLS:\n",
    "        \n",
    "    '''Class to generate the summary of an Ordinary Least Squares regression model.'''\n",
    "    def __init__(self,xData,ydata):\n",
    "        self.X=xData\n",
    "        self.y=ydata\n",
    "        self.summary=self.statModel()\n",
    "    def statModel(self):\n",
    "        '''Generates OLS summary for the provided data.'''\n",
    "        X = sm.add_constant(self.X)\n",
    "        model = sm.OLS(self.y, X).fit()\n",
    "        summary = model.summary()\n",
    "        return summary\n",
    "\n",
    "\n",
    "read_method_=pd.read_csv\n",
    "path_=r\"C:\\Users\\Admin\\Desktop\\Polestar_Work\\Day-1_Preprocesing_2\\Day-1_Preprocesing\\housing\\housing.csv\"\n",
    "loaderObject = Loading(path_,read_method_)\n",
    "data_ = loaderObject.data\n",
    "\n",
    "\n",
    "strategy_=\"drop\"\n",
    "fillNaObject = FillNa(data_, strategy_)\n",
    "filledData_=fillNaObject.filledData\n",
    "\n",
    "\n",
    "categoricalColumns_=[\"ocean_proximity\"]\n",
    "oneHotEncodedDataObject=OneHotEncoding(filledData_,categoricalColumns_)\n",
    "oneHotEncodedData_=oneHotEncodedDataObject.oneHotEncodedData\n",
    "\n",
    "\n",
    "method_outlier_=\"iqr\"\n",
    "outlierObject=Outlier(oneHotEncodedData_,method_outlier_)\n",
    "cleanedData_=outlierObject.cleanedData\n",
    "\n",
    "targetColumn_=['median_house_value']\n",
    "splittingDataObject=SplittingData(cleanedData_,targetColumn_)\n",
    "XData,yData=splittingDataObject.X,splittingDataObject.y\n",
    "\n",
    "\n",
    "testSize=0.2\n",
    "randomState=15\n",
    "trainTestSplitObject=TrainTestSplit(XData, yData, testingSize=testSize, random_State=randomState)\n",
    "\n",
    "xtrain_=trainTestSplitObject.xTrain\n",
    "ytrain_=trainTestSplitObject.yTrain\n",
    "xtest_=trainTestSplitObject.xTest\n",
    "ytest_=trainTestSplitObject.yTest\n",
    "\n",
    "\n",
    "\n",
    "method_ = 'yeo-johnson'\n",
    "standardizationObject = Standardization(Xtrain=xtrain_, XTest=xtest_, method=method_)\n",
    "standardizedXTrain=standardizationObject.xTrain_transformed\n",
    "standardizedXTest=standardizationObject.xTest_transformed\n",
    "\n",
    "\n",
    "model=Ridge()\n",
    "modelFitObject = ModelFitting(model, standardizedXTrain, ytrain_)\n",
    "fittedModel=modelFitObject.fittedModel\n",
    "\n",
    "\n",
    "regressionMetrics_=mean_absolute_percentage_error \n",
    "evaluationObject=Evaluation(standardizedXTest,ytest_,regressionMetrics_,fittedModel)\n",
    "evaluationObject.score\n",
    "\n",
    "statModelOLSObject=StatModelOLS(XData,yData)\n",
    "print(statModelOLSObject.summary)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
